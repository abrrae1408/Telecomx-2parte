# -*- coding: utf-8 -*-
"""Telecomx 2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_SXgJEJ2r4nzajCs46xq0obOYxn3Z3p0

Analisis Técnico de Datos TELECOMX Parte 2
"""

# Commented out IPython magic to ensure Python compatibility.
# Instalar la librería imblearn
# %pip install imblearn

# Importar las librerías necesarias
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, OneHotEncoder, RobustScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve
from imblearn.over_sampling import SMOTE
import matplotlib.pyplot as plt
import seaborn as sns

"""##Extracción de datos"""

# Cargar el dataset
df = pd.read_csv('/content/TelecomX_Clean.csv')
df.head()

df.info()

"""##Limpieza y Procesamiento de los Datos"""

# Convertir espacios en blanco a NaN y luego a tipo numérico para 'account_Charges_Total'
df['account_Charges_Total'] = pd.to_numeric(df['account_Charges_Total'], errors='coerce')

# Imputar valores NaN en 'account_Charges_Total' con la mediana de la columna
median_total_charges = df['account_Charges_Total'].median()
df['account_Charges_Total'].fillna(median_total_charges, inplace=True)

print(f"\nValores nulos después de la imputación en 'account_Charges_Total': {df['account_Charges_Total'].isnull().sum()}")

"""Conversion de variable Churn"""

# Convertir la variable objetivo 'Churn' a numérica (Yes=1, No=0)
df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})

# Convertir 'customer_SeniorCitizen' a string para que sea tratada como categórica para One-Hot Encoding
if 'customer_SeniorCitizen' in df.columns:
    df['customer_SeniorCitizen'] = df['customer_SeniorCitizen'].astype(str)

# Identificación de características categóricas y numéricas
# Excluir 'Churn' de las columnas a codificar/escalar ya que es la variable objetivo
categorical_cols = df.select_dtypes(include=['object']).columns.tolist()
numerical_cols = df.select_dtypes(include=['number']).columns.tolist()

if 'Churn' in numerical_cols:
    numerical_cols.remove('Churn')

print(f"\nColumnas categóricas identificadas: {categorical_cols}")
print(f"Columnas numéricas identificadas: {numerical_cols}")

"""##Codificación de Variables Categóricas (One-Hot Encoding)

Aplicamos One-Hot Encoding a todas las columnas categóricas para convertirlas en un formato numérico que los modelos puedan procesar.
"""

# Codificación One-Hot para características categóricas
# drop_first=False for demonstration; consider drop_first=True in practice to avoid multicollinearity
df_encoded = pd.get_dummies(df, columns=categorical_cols, drop_first=False)

print("\nDataFrame after encoding (first 5 rows):")
print(df_encoded.head())

"""Escalado de Características Numéricas (RobustScaler)

Escalamos las características numéricas para asegurar que todas contribuyan equitativamente al modelo, utilizando RobustScaler para manejar posibles valores atípicos.
"""

# Escalado Robusto para características numéricas
scaler = RobustScaler()
df_encoded[numerical_cols] = scaler.fit_transform(df_encoded[numerical_cols])

print("\nDataFrame after encoding and scaling (first 5 rows):")
print(df_encoded.head())

"""##Balanceo de los Datos"""

# Drop rows where 'Churn' is NaN
df_cleaned = df_encoded.dropna(subset=['Churn'])

# Separar características (X) y variable objetivo (y)
X = df_cleaned.drop('Churn', axis=1)
y = df_cleaned['Churn']

# Abordar el desequilibrio de clases con SMOTE
print(f"\nDistribución de la clase 'Churn' antes de SMOTE:\n{y.value_counts()}")
smote = SMOTE(random_state=42)
X_resampled, y_resampled = smote.fit_resample(X, y)
print(f"\nDistribución de la clase 'Churn' después de SMOTE:\n{y_resampled.value_counts()}")

"""##División del Conjunto de Datos

Dividimos el dataset en conjuntos de entrenamiento (80%) y prueba (20%), asegurando una distribución estratificada de la variable objetivo.
"""

# División de datos en conjuntos de entrenamiento y prueba (80% entrenamiento, 20% prueba)
X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)

print(f"\nDimensiones del conjunto de entrenamiento (X_train, y_train): {X_train.shape}, {y_train.shape}")
print(f"Dimensiones del conjunto de prueba (X_test, y_test): {X_test.shape}, {y_test.shape}")

"""##Análisis de Correlación"""

# Análisis de correlación para características numéricas (después de escalado)
plt.figure(figsize=(10, 8))
sns.heatmap(df_encoded[numerical_cols + ['Churn']].corr(), annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Matriz de Correlación de Características Numéricas con Churn')
plt.show()

"""Entrenamos dos modelos de clasificación: Regresión Logística y Bosque Aleatorio.

 Entrenamiento del Modelo de Regresión Logística
"""

# Modelo 1: Regresión Logística
print("\n--- Entrenamiento de Regresión Logística ---")
log_reg_model = LogisticRegression(random_state=42, solver='liblinear') # 'liblinear' es bueno para datasets pequeños y L1/L2
log_reg_model.fit(X_train, y_train)
y_pred_log_reg = log_reg_model.predict(X_test)
y_prob_log_reg = log_reg_model.predict_proba(X_test)[:, 1]

"""Entrenamiento del Modelo de Bosque Aleatorio"""

# Modelo 2: Bosque Aleatorio
print("\n--- Entrenamiento de Bosque Aleatorio ---")
rf_model = RandomForestClassifier(random_state=42, n_estimators=100) # n_estimators: número de árboles
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)
y_prob_rf = rf_model.predict_proba(X_test)[:, 1]

"""Evaluación de Regresión Logística"""

print("\n--- Evaluación del Modelo de Regresión Logística ---")
print("Reporte de Clasificación:")
print(classification_report(y_test, y_pred_log_reg))
print("\nMatriz de Confusión:")
print(confusion_matrix(y_test, y_pred_log_reg))
auc_log_reg = roc_auc_score(y_test, y_prob_log_reg)
print(f"AUC: {auc_log_reg:.4f}")

"""Evaluación de Bosque Aleatorio"""

print("\n--- Evaluación del Modelo de Bosque Aleatorio ---")
print("Reporte de Clasificación:")
print(classification_report(y_test, y_pred_rf))
print("\nMatriz de Confusión:")
print(confusion_matrix(y_test, y_pred_rf))
auc_rf = roc_auc_score(y_test, y_prob_rf)
print(f"AUC: {auc_rf:.4f}")

"""Visualización de Curvas ROC"""

# Visualización de la Curva ROC
fpr_log_reg, tpr_log_reg, _ = roc_curve(y_test, y_prob_log_reg)
fpr_rf, tpr_rf, _ = roc_curve(y_test, y_prob_rf)

plt.figure(figsize=(8, 6))
plt.plot(fpr_log_reg, tpr_log_reg, label=f'Regresión Logística (AUC = {auc_log_reg:.2f})')
plt.plot(fpr_rf, tpr_rf, label=f'Bosque Aleatorio (AUC = {auc_rf:.2f})')
plt.plot([0, 1], [0, 1], 'k--', label='Aleatorio') # Línea de referencia para un clasificador aleatorio
plt.xlabel('Tasa de Falsos Positivos')
plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)')
plt.title('Curva ROC')
plt.legend()
plt.show()

"""Importancia de Características (Regresión Logística)"""

print("\n--- Importancia de Características (Regresión Logística) ---")
# Los coeficientes de la regresión logística indican la importancia y dirección
# Es importante que las características estén escaladas para comparar magnitudes
log_reg_coefficients = pd.DataFrame({
    'Feature': X_train.columns,
    'Coefficient': log_reg_model.coef_[0], # Access the first row for binary classification
    'Odds Ratio': np.exp(log_reg_model.coef_[0]) # Calculate Odds Ratios using the first row
}).sort_values(by='Odds Ratio', ascending=False)
print(log_reg_coefficients)

"""Importancia de Características (Bosque Aleatorio)"""

print("\n--- Importancia de Características (Bosque Aleatorio) ---")
# La importancia de las características en Random Forest se basa en la reducción de la impureza
rf_feature_importances = pd.DataFrame({
    'Feature': X_train.columns,
    'Importance': rf_model.feature_importances_
}).sort_values(by='Importance', ascending=False)
print(rf_feature_importances)

"""##Conclusion Estrategica

Basándonos en el análisis de los modelos de Regresión Logística y Bosque Aleatorio,
los principales factores que influyen en la cancelación de clientes en Telecom X son:

1.  **Tipo de Contrato (Mes a Mes):** Los clientes con contratos mensuales (`account_Contract_Month-to-month`)
    muestran una probabilidad significativamente mayor de fuga. Esto se debe a la flexibilidad
    y el bajo compromiso que ofrecen estos contratos, lo que facilita el cambio a la competencia.

2.  **Antigüedad del Cliente (`customer_tenure`):** Existe una fuerte correlación inversa;
    los clientes con menor antigüedad en la empresa son considerablemente más propensos a la fuga.
    Esto subraya la importancia de las estrategias de incorporación y retención temprana.

3.  **Servicio de Internet (Fibra Óptica):** Los clientes con servicio de fibra óptica
    (`internet_InternetService_Fiber optic`) parecen tener una mayor propensión a la fuga.
    Esto podría indicar problemas de calidad percibida, expectativas no cumplidas o una mayor
    sensibilidad a las ofertas de la competencia en este segmento de alta velocidad.

4.  **Método de Pago (Cheque Electrónico):** El uso del cheque electrónico
    (`account_PaymentMethod_Electronic check`) como método de pago se asocia con una mayor
    probabilidad de fuga. Esto podría ser un indicador de un segmento de clientes con menor
    fidelización o con patrones de comportamiento financiero específicos que los hacen más volátiles.

5.  **Ausencia de Servicios Adicionales (Seguridad en Línea, Soporte Técnico):** La falta de
    servicios como seguridad en línea (`internet_OnlineSecurity_No`) y soporte técnico
    (`internet_TechSupport_No`) también contribuye a la fuga. Estos servicios actúan como
    "adhesivos" que aumentan el valor percibido y el compromiso del cliente con la empresa.

6.  **Cargos Mensuales (`account_Charges_Monthly`):** Cargos mensuales más altos pueden
    indicar un mayor riesgo de fuga, especialmente si los clientes no perciben un valor
    proporcional a lo que pagan.

Estos hallazgos sugieren que Telecom X debería enfocar sus esfuerzos de retención en clientes
con contratos a corto plazo y baja antigüedad, así como en aquellos con servicio de fibra óptica
y método de pago por cheque electrónico. Ofrecer incentivos para contratos a largo plazo,
mejorar la experiencia de los nuevos clientes y destacar el valor de los servicios adicionales
serán estrategias clave para mitigar la fuga.
"""

